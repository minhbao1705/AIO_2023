{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    numerator = np.dot(x, y)\n",
    "    denominator = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_based_matching(left_img, right_img, disparity_range, kernel_size=5, save_result=True):\n",
    "    # Read left, right images then convert to grayscale\n",
    "    left  = cv2.imread(left_img, 0)\n",
    "    right = cv2.imread(right_img, 0)\n",
    "\n",
    "    left  = left.astype(np.float32)\n",
    "    right = right.astype(np.float32)\n",
    "\n",
    "    height, width = left.shape[:2]\n",
    "\n",
    "    # Create blank disparity map\n",
    "    depth = np.zeros((height, width), np.uint8)\n",
    "    kernel_half = int((kernel_size - 1) / 2)\n",
    "    scale = 3\n",
    "\n",
    "    for y in range(kernel_half, height-kernel_half):\n",
    "        for x in range(kernel_half, width-kernel_half):\n",
    "            # Find j where cost has minimum value\n",
    "            disparity = 0\n",
    "            cost_optimal  = -1\n",
    "\n",
    "            for j in range(disparity_range):\n",
    "                d = x - j\n",
    "                cost = -1\n",
    "                if (d - kernel_half) > 0:\n",
    "                    wp = left[(y-kernel_half):(y+kernel_half)+1, (x-kernel_half):(x+kernel_half)+1]\n",
    "                    wqd = right[(y-kernel_half):(y+kernel_half)+1, (d-kernel_half):(d+kernel_half)+1]\n",
    "\n",
    "                    wp_flattened = wp.flatten()\n",
    "                    wqd_flattened = wqd.flatten()\n",
    "\n",
    "                    cost = cosine_similarity(wp_flattened, wqd_flattened)\n",
    "\n",
    "                if cost > cost_optimal:\n",
    "                    cost_optimal = cost\n",
    "                    disparity = j\n",
    "\n",
    "            # Let depth at (y, x) = j (disparity)\n",
    "            # Multiply by a scale factor for visualization purpose\n",
    "            depth[y, x] = disparity * scale\n",
    "\n",
    "    if save_result == True:\n",
    "        print('Saving result...')\n",
    "        # Save results\n",
    "        cv2.imwrite('window_based_cosine_similarity.png', depth)\n",
    "        cv2.imwrite('window_based_cosine_similarity_color.png', cv2.applyColorMap(depth, cv2.COLORMAP_JET))\n",
    "\n",
    "    print('Done.')\n",
    "\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m,left)\n\u001b[0;32m     10\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m,right)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "left_img_path = './Aloe/Aloe_left_1.png'\n",
    "right_img_path = 'D:/AIO-2023-main/230730 - Statistic Exercise - Dr_Dinh_Vinh/Aloe/Aloe_right_2.png'\n",
    "disparity_range = 64\n",
    "kernel_size = 5\n",
    "\n",
    "left = cv2.imread(left_img_path)\n",
    "right = cv2.imread(right_img_path)\n",
    "\n",
    "cv2.imshow('left',left)\n",
    "cv2.imshow('right',right)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m depth \u001b[38;5;241m=\u001b[39m window_based_matching(\n\u001b[0;32m      2\u001b[0m     left_img_path,\n\u001b[0;32m      3\u001b[0m     right_img_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     save_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mapplyColorMap(depth, cv2\u001b[38;5;241m.\u001b[39mCOLORMAP_JET))\n\u001b[0;32m     10\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n"
     ]
    }
   ],
   "source": [
    "depth = window_based_matching(\n",
    "    left_img_path,\n",
    "    right_img_path,\n",
    "    disparity_range,\n",
    "    kernel_size=kernel_size,\n",
    "    save_result=False\n",
    ")\n",
    "cv2.imshow(depth)\n",
    "cv2.imshow(cv2.applyColorMap(depth, cv2.COLORMAP_JET))\n",
    "cv2.waitKey()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
